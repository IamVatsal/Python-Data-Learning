{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3e75ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5cffa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[-1.56035211 -0.0309776  -0.62092842]\n",
      " [-1.46458049  1.41194612 -0.47673214]\n",
      " [-0.78046921  1.07026774 -1.2822926 ]\n",
      " [-1.3274789   0.12633764  0.86219372]]\n",
      "W1: \n",
      " [[ 0.0696737  -0.03345652 -0.09975261  0.15989083  0.33140753]\n",
      " [ 0.09877705  0.01238663  0.07427854 -0.03939559  0.01481158]\n",
      " [-0.04122345 -0.01607151  0.01395315  0.02854694 -0.0281262 ]]\n",
      "W2: \n",
      " [[ 0.17109073 -0.01497666]\n",
      " [ 0.06903067  0.10952095]\n",
      " [ 0.13384087 -0.13689817]\n",
      " [ 0.04864276  0.07535217]\n",
      " [ 0.03634646 -0.03147105]]\n",
      "b1: \n",
      " [[0. 0. 0. 0. 0.]]\n",
      "b2: \n",
      " [[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Random Seed For Reproducibility\n",
    "np.random.seed(50)\n",
    "\n",
    "# Input data (4 samples, 3 features)\n",
    "X = np.random.randn(4, 3)\n",
    "\n",
    "# Layer 1 parameters\n",
    "W1 = np.random.randn(3, 5) * 0.1 # (input_features, hidden_neurons)\n",
    "b1 = np.zeros((1,5))             # (1, hidden_neurons)\n",
    "\n",
    "# Layer 2 parameters\n",
    "W2 = np.random.randn(5, 2) * 0.1 # (hidden_neurons, output_neurons)\n",
    "b2 = np.zeros((1, 2))            # (1, output_neurons)    \n",
    "\n",
    "print(\"X: \\n\", X)\n",
    "print(\"W1: \\n\", W1)\n",
    "print(\"W2: \\n\", W2)\n",
    "print(\"b1: \\n\", b1)\n",
    "print(\"b2: \\n\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ebf533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # stability trick\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5802e00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1 shape: \n",
      " (4, 5)\n",
      "Z1: \n",
      " [[-0.08617857  0.0617995   0.14468431 -0.26599122 -0.50010692]\n",
      " [ 0.05707767  0.07415082  0.2443211  -0.30340667 -0.45105119]\n",
      " [ 0.10420023  0.05997716  0.13945974 -0.20355922 -0.206735  ]\n",
      " [-0.1155537   0.03212097  0.15383397 -0.19261586 -0.46231548]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A1 shape: \n",
      " (4, 5)\n",
      "A1: \n",
      " [[0.         0.0617995  0.14468431 0.         0.        ]\n",
      " [0.05707767 0.07415082 0.2443211  0.         0.        ]\n",
      " [0.10420023 0.05997716 0.13945974 0.         0.        ]\n",
      " [0.         0.03212097 0.15383397 0.         0.        ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Z2 shape: \n",
      " (4, 2)\n",
      "Z2: \n",
      " [[ 0.02363074 -0.01303868]\n",
      " [ 0.04758429 -0.02618088]\n",
      " [ 0.04063337 -0.0140836 ]\n",
      " [ 0.0228066  -0.01754167]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Network Output:\n",
      " [[ 0.02363074 -0.01303868]\n",
      " [ 0.04758429 -0.02618088]\n",
      " [ 0.04063337 -0.0140836 ]\n",
      " [ 0.0228066  -0.01754167]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Probabilities:\n",
      " [[0.50916633 0.49083367]\n",
      " [0.51843293 0.48156707]\n",
      " [0.51367583 0.48632417]\n",
      " [0.5100857  0.4899143 ]]\n",
      "Predicted classes: [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "\n",
    "# Layer 1 (Linear)\n",
    "Z1 = np.dot(X, W1) + b1\n",
    "print(\"Z1 shape: \\n\", Z1.shape)\n",
    "print(\"Z1: \\n\",Z1)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "# ReLU Activation\n",
    "A1 = ReLU(Z1)\n",
    "print(\"A1 shape: \\n\", A1.shape)\n",
    "print(\"A1: \\n\", A1)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "# Layer 2 (Linear)\n",
    "Z2 = np.dot(A1, W2) + b2\n",
    "print(\"Z2 shape: \\n\", Z2.shape)\n",
    "print(\"Z2: \\n\",Z2)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"Network Output:\\n\", Z2)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "output = softmax(Z2)\n",
    "print(\"Probabilities:\\n\", output)\n",
    "print(\"Predicted classes:\", np.argmax(output, axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
